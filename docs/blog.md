---
title: スプレッドシートで社内FAQを管理して Bedrock Knowledge Bases で検索可能にするパイプラインを作った
tags: AWS Bedrock KnowledgeBases GoogleAppsScript Lambda
---

## はじめに

社内ナレッジ（FAQ）を RAG で検索可能にしたい。でもナレッジの入力・管理はビジネスサイドに任せたい。

この2つを両立するために、**スプレッドシートを UI として、Amazon Bedrock Knowledge Bases でベクトル検索できるパイプライン**を構築しました。

LayerX さんが[スプレッドシートでナレッジベースを管理する事例](https://tech.layerx.co.jp/)を紹介されていたのを参考にしつつ、自分たちの環境に合わせて実装しています。

## 何を作ったか

スプレッドシートに Q&A を自然言語で書いて、カスタムメニューから「追加」を押すだけで、Bedrock Knowledge Bases に同期されて検索可能になるパイプラインです。

```
スプレッドシート (UI) ← ビジネスサイドが自然言語で入力
    ↓ カスタムメニュー操作
GAS (Google Apps Script) ← No自動生成(UUIDv4フル)、バリデーション
    ↓ HTTP POST (JSON / job_id + row_number 付き)
API Gateway (APIキー認証)
    ↓
Lambda (Python 3.12) ← 自然言語 → 構造化Markdown 変換
    ↓
S3 → Knowledge Bases → S3 Vectors
```

### ポイント

- **入力者は Markdown を意識しない**。自然言語で書くだけ。Markdown 変換は Lambda 側で行う
- **スプレッドシートが UI** なので、ビジネスサイドの学習コストはほぼゼロ
- **ベクトルストアに S3 Vectors を採用**。OpenSearch Serverless より安価でシンプル

## スプレッドシートの設計

### 列構成

| 列 | 内容 | 備考 |
|----|------|------|
| A | チェックボックス | 操作対象の行を選択 |
| B | No | `KB-{UUIDv4}` 形式。GAS で自動生成 |
| C | 質問 | 自然言語で入力 |
| D | 回答 | 自然言語で入力 |
| E | カテゴリ | メタデータフィルタリング用 |
| F | 参照URL | ソース元URL |
| G | 更新日 | 最終同期日時（自動） |
| H | ステータス | 未同期 / 同期済 / deleting / deleted / エラー |

ビジネスサイドが触るのは C〜F 列だけ。A列でチェックしてメニューから操作すると、B/G/H列は自動で埋まります。

### カスタムメニュー

「ナレッジ同期」メニューに3つの操作を用意しています。

| メニュー | 機能 | 対象 |
|----------|------|------|
| 追加 | 新規ナレッジを同期 | No が空の行 |
| 差分更新 | 既存ナレッジを更新 | No がある行 |
| 削除 | S3 / KB から論理削除 | No がある行 |

### ステータス遷移

ステータスは5種類あり、操作結果に応じて以下のように遷移します。

```
(新規入力) → 未同期
未同期 → [追加成功] → 同期済
未同期 → [追加失敗] → エラー
同期済 → [差分更新成功] → 同期済（更新日が更新）
同期済 → [削除実行] → deleting
deleting → [ingestion完了確認] → deleted
エラー → [再同期成功] → 同期済
```

削除は `deleting` → `deleted` の2段階です。Lambda が S3 メタデータの `active` フラグを `"false"` にした時点で `deleting`、Knowledge Bases の ingestion が完了して検索結果から除外されたことを確認してから `deleted` に遷移します。検索にまだ出ている期間が可視化されるので、運用上の混乱を防げます。

## 設計上のこだわり

### Markdown 変換を Lambda 側に寄せた理由

当初はスプレッドシート上で Markdown を書いてもらう案もありましたが、以下の理由で Lambda 側で変換する方針にしました。

- **入力者にフォーマットを意識させたくない**。Markdown の書き方を知らない人もいる
- **フォーマットの統一**。人によって書き方が違うとベクトル化の品質にばらつきが出る
- **変換ロジックの変更が容易**。Lambda のコードを変えるだけで、全ナレッジの形式を統一できる

### 構造化 Markdown テンプレート

最初は `# {質問文}` のシンプルな H1 形式にしていましたが、検索時に質問文が過度に重み付けされる問題がありました。`## Question` / `## Answer` のセクション分けに変更することで、質問と回答を均等に検索対象にできるようになりました。

```markdown
# FAQ

## Question
有給休暇の申請方法を教えてください

## Answer
社内ポータルの「勤怠管理」メニューから「休暇申請」を選択してください。

申請は希望日の3営業日前までに行う必要があります。

---
no: KB-550e8400-e29b-41d4-a716-446655440000
category: 人事
source: https://...
```

フッター部分に `no`、`category`、`source` を入れているのは、Knowledge Bases が Markdown 本文もチャンクとして取り込むためです。メタデータファイルとは別に、本文中にもこれらの情報を持たせることで、検索結果からナレッジの出所をたどりやすくなります。

### No の自動生成と事故防止

No（ナレッジ ID）は `KB-{UUIDv4}` 形式で、GAS 側で自動生成します。`Utilities.getUuid()` で UUIDv4 を生成し、フルの36桁をそのまま使用します。当初は UUID の先頭8桁だけを使う設計でしたが、運用が長くなるほど衝突リスクが現実的になるためフル UUID に変更しました。

事故防止のポイント:

- **B列はシート保護**で手動編集不可にする
- **追加時のみ生成**。既に No がある行は追加対象から除外（二重生成防止）
- **API 呼び出し前に No を書き込み**。通信失敗しても No は確定済み。ステータスを「エラー」にすることで再送可能

```javascript
// No を生成してシートに即座に書き込み（API呼び出しの前）
var no = generateNo();
sheet.getRange(row, COL.NO).setValue(no);
```

```javascript
function generateNo() {
  return "KB-" + Utilities.getUuid();
}
```

### job_id と row_number による安全な書き戻し

API のリクエストには `job_id`（リクエスト単位の UUID）と `items[].row_number`（スプレッドシートの行番号）を含めています。

```json
{
  "job_id": "uuid-for-this-request",
  "action": "add",
  "items": [
    { "row_number": 2, "no": "KB-550e8400-...", "question": "...", "answer": "...", ... },
    { "row_number": 3, "no": "KB-6ba7b810-...", "question": "...", "answer": "...", ... }
  ]
}
```

Lambda はレスポンスにも `row_number` をそのまま返すので、GAS 側は行番号で直接対応する行を特定してステータスを書き戻せます。初期設計では `no` でマッチングしていましたが、行の並び替えや重複 No が発生した場合にずれるリスクがあったため、`row_number` ベースに変更しました。

## 実装

### GAS（Google Apps Script）

GAS は `config.gs`・`api.gs`・`Code.gs` の3ファイル構成にしています。

`config.gs` には API Gateway のエンドポイント URL、APIキー、そして列番号のマッピングを定義しています。列番号をハードコードせず `COL.QUESTION` のように名前で参照できるようにしておくと、列を追加・入れ替えたときに修正箇所が `config.gs` だけで済みます。

`api.gs` は API Gateway への HTTP POST を担当するモジュールです。GAS の `UrlFetchApp.fetch()` を使い、`x-api-key` ヘッダーで認証しています。`muteHttpExceptions: true` を指定することで、4xx / 5xx でも例外にならず、ステータスコードで分岐できるようにしました。エラー時はレスポンスボディも含めて throw するので、呼び出し元でユーザーに通知できます。

`Code.gs` がメインのファイルで、カスタムメニューの登録と3つの同期操作（追加・差分更新・削除）の処理を持ちます。

追加処理の流れを疑似コードで示します。

```
1. チェックが ON の行を取得
2. No が空の行だけをフィルタリング（既に追加済みの行を除外）
3. 対象が 0 件なら終了
4. 確認ダイアログで件数を表示 → キャンセル可
5. 各行に KB-{UUIDv4} を生成し、B列に即座に書き込み
6. job_id を生成し、各行データに row_number を付与
7. JSON にまとめて API Gateway へ POST
8. レスポンスの row_number を使って G列（更新日）と H列（ステータス）に反映
9. 全行のチェックボックスを OFF に戻す
```

ここで重要なのがステップ5〜7の順番です。No をシートに書き込んでから API を呼ぶことで、通信が失敗しても No は確定済みになります。ステータスを「エラー」にしておけば、次回「差分更新」で再送できます。No を API 呼び出し後に書き込む設計だと、通信途中で GAS がタイムアウトした場合に「S3 には存在するがシートに No がない」孤児データが生まれてしまいます。

差分更新と削除も基本的な流れは同じで、違いはフィルタ条件（No がある行のみ対象）と、API に送る `action` パラメータだけです。削除の場合はシートの行自体は消さず、ステータスを `deleting` にして履歴を残します。

### Lambda（Python 3.12）

Lambda は単一関数で、リクエストボディの `action` フィールド（`add` / `update` / `delete`）で処理を分岐します。Lambda を複数に分けず1つにまとめたのは、どの操作も「S3 にファイルを書き込み → Knowledge Bases のインジェスションを起動」という同じパターンだからです。

#### API 設計の考え方

エンドポイントは `POST /knowledge` の1つだけ。GAS から送られてくる JSON に `job_id`、`action`、`items`（配列）を持たせ、1回のリクエストで複数のナレッジをまとめて処理できるようにしました。チェックした10行を一括で追加する場合でも、API 呼び出しは1回で済みます。

`items` には `row_number`・No・質問・回答・カテゴリ・参照URL が含まれます。質問と回答はスプレッドシートに入力された自然言語がそのまま入ります。レスポンスには `job_id` をエコーバックし、各 result に `row_number` を含めて返すことで、GAS 側での書き戻しを安全に行えます。

#### Markdown 変換の設計

Lambda の中核は、自然言語の Q&A を Knowledge Bases に適した構造化 Markdown に変換する部分です。

- **質問** → `## Question` セクション
- **回答** → `## Answer` セクション
- **メタ情報** → フッター（`---` 区切り以降に `no`、`category`、`source`）

加えて、改行コードの正規化（`\r\n` → `\n`）と、3つ以上連続する空行の圧縮、行末空白の除去を行います。スプレッドシートからのコピペで混入しがちな余計な改行を除去し、ベクトル化時のノイズを減らすためです。

たとえば「営業時間は？」「10:00〜19:00です。」という Q&A は、以下の Markdown に変換されます。

```markdown
# FAQ

## Question
営業時間は？

## Answer
10:00〜19:00です。

---
no: KB-550e8400-e29b-41d4-a716-446655440000
category: 総務
source:
```

#### S3 保存とメタデータの仕組み

各ナレッジは S3 上に2ファイルのペアで保存されます。

- `knowledge/KB-550e8400-e29b-41d4-a716-446655440000.md` — 構造化 Markdown
- `knowledge/KB-550e8400-e29b-41d4-a716-446655440000.metadata.json` — メタデータ

メタデータファイルは Knowledge Bases の **S3 メタデータフィルタリング規約** に準拠した形式にする必要があります。具体的には `metadataAttributes` キーの下にフラットなキーバリューで格納します。

```json
{
  "metadataAttributes": {
    "no": "KB-550e8400-e29b-41d4-a716-446655440000",
    "category": "人事",
    "source_url": "https://...",
    "updated_at": "2026-02-16T12:00:00+09:00",
    "active": "true"
  }
}
```

`category` でフィルタリングすれば「人事カテゴリだけから探す」といった検索が可能です。`source_url` で回答時にソース元のリンクを提示できます。`active` フラグで論理削除を実現しており、検索時に `active = "true"` でフィルタリングすることで削除済みナレッジを除外します。

差分更新は同じ S3 キーに対して上書き PUT するだけです。削除は `.metadata.json` の `active` を `"false"` に更新する論理削除方式で、ファイル自体は残します。物理削除だと ingestion のタイミングによっては「検索にまだ出る」期間が発生しますが、論理削除なら次回の ingestion でメタデータフィルタにより除外されます。

#### Knowledge Bases のインジェスション

S3 のファイル操作がすべて完了した後、`start_ingestion_job()` を **1回だけ** 呼びます。アイテムごとに呼ぶのではなく、バッチの最後にまとめて1回です。これは Knowledge Bases 側がインジェスションジョブ単位で S3 バケット全体をスキャンする仕組みのためで、10件追加しても1回の呼び出しで全件が反映されます。

インジェスションは非同期で実行されるため、Lambda のレスポンスは S3 への書き込み成功をもって即座に返します。ベクトル化の完了を待つと GAS のタイムアウト（6分）に引っかかるリスクがあるためです。実運用ではインジェスションの完了まで数十秒〜数分かかりますが、社内 FAQ の更新頻度を考えればこの遅延は許容範囲です。

## AWS リソース構成

リソースの命名は `{project}-{env}-{resource}-{role}` で統一しています。プロジェクト識別子は `kp`（knowledge pipeline の略）です。こうしておくと、AWS コンソールやCLIで `kp-` で検索すれば関連リソースが一覧でき、他プロジェクトとの混同を防げます。

| リソース | 命名 | 役割 |
|----------|------|------|
| S3 | `kp-dev-s3-data` | Markdown + メタデータの原本保管 |
| Lambda | `kp-dev-lambda-handler` | 変換・S3操作・KB同期 |
| API Gateway | `kp-dev-apigw-knowledge` | REST API + APIキー認証 |
| Knowledge Base | `kp-dev-kb-faq` | テキスト → ベクトル変換 |
| S3 Vectors | `kp-dev-s3vectors-faq` | ベクトルストア（検索用） |
| IAM ロール (Lambda) | `kp-dev-iam-lambda-exec` | Lambda の実行権限 |
| IAM ロール (KB) | `kp-dev-iam-kb-exec` | KB の S3 / Bedrock アクセス権限 |
| IAM ユーザー | `kp-dev-iam-deploy` | デプロイ・運用用 |

IAM はプロジェクト単位で専用ユーザー（`kp-dev-iam-deploy`）を作り、`kp-*` リソースにだけアクセスできるカスタムポリシーを付与しています。共用の管理者アカウントを使い回さないことで、万が一キーが漏洩しても影響範囲をこのプロジェクトだけに限定できます。

### S3 / Knowledge Bases / S3 Vectors の関係

この3つの関係が最初わかりにくかったので補足します。

```
S3 (kp-dev-s3-data)               ← 原本の保管場所（Markdown）
    ↓ Knowledge Bases が読み取り
Knowledge Bases (kp-dev-kb-faq)    ← テキストをベクトルに変換するエンジン
    ↓ 変換結果を保存
S3 Vectors (kp-dev-s3vectors-faq)  ← ベクトルデータを保持し類似度検索を実行
```

| | S3 | Knowledge Bases | S3 Vectors |
|---|---|---|---|
| 例えると | 本棚 | 索引を作る人 | 索引帳 |
| 中身 | Markdown + JSON | 設定のみ（データなし） | ベクトル数値 |
| 書き込む人 | Lambda | - | Knowledge Bases |
| 役割 | 原本保管 | テキスト→ベクトル変換 | 類似度検索 |

Knowledge Bases は Titan Embeddings V2 モデルを使ってテキストを 1024 次元のベクトルに変換し、S3 Vectors に格納します。検索時はクエリもベクトル化して、コサイン類似度で最も近いナレッジを返します。

## 動作確認

実際にスプレッドシートから追加してみた結果を紹介します。

### スプレッドシートでの操作

質問「営業時間は？」、回答「10:00〜19:00です。」と入力し、A列のチェックボックスを ON にして「ナレッジ同期 > 追加」を実行します。

確認ダイアログで「1 件のナレッジを追加します。よろしいですか？」と表示され、OK を押すと処理が始まります。数秒で B列に No（`KB-550e8400-e29b-41d4-a716-446655440000`）が自動生成され、G列に更新日時、H列のステータスが「同期済」に変わりました。チェックボックスも自動で OFF に戻ります。

### S3 の確認

S3 コンソールで `kp-dev-s3-data/knowledge/` を開くと、`.md` と `.metadata.json` が作成されていました。Markdown ファイルの中身は、`## Question` と `## Answer` のセクションに分かれた構造化テンプレートです。メタデータには `active: "true"` が設定されています。

### Knowledge Bases でのベクトル検索

インジェスションが完了した後、AWS CLI の `retrieve` コマンドで「営業時間」と検索すると、類似度スコア **0.73** でヒットしました。スプレッドシートに書いた自然言語が、構造化 Markdown に変換され、ベクトル化されて検索可能になっていることが確認できます。

スコア 0.73 は完全一致ではなく意味的な類似度で算出されています。今後「何時まで？」や「開いてる時間」といった表現の揺れに対してどの程度スコアが出るかを検証していく予定です。

## ベクトルストアに S3 Vectors を選んだ理由

Knowledge Bases のベクトルストアには OpenSearch Serverless、Aurora PostgreSQL、Pinecone、Redis、そして S3 Vectors といった選択肢があります。

最初の候補は OpenSearch Serverless でしたが、最低でも月数万円のコストがかかります。開発環境を含めると倍になり、社内 FAQ という用途に対しては過剰でした。Aurora PostgreSQL は既に RDS を使っていれば追加コストが少ないのですが、このプロジェクトでは RDS を使っておらず、新規に構築するのは運用負荷が高すぎます。Pinecone や Redis は外部サービスとの契約が必要で、AWS 内で完結したいという方針と合いませんでした。

S3 Vectors は 2025 年にリリースされた比較的新しいサービスで、S3 ベースの低コストなベクトルストアです。レイテンシは OpenSearch に劣りますが、社内 FAQ の検索であればリアルタイム性への要求は高くなく、十分に許容できるレベルでした。コストの安さとセットアップのシンプルさを重視して S3 Vectors を採用しています。

## 今後の改善点

### ingestion job の分離

現状は Lambda 内で `start_ingestion_job()` を同期的に呼んでいます。更新件数が増えると Lambda のタイムアウトリスクや、短時間に複数回 ingestion が走る無駄が発生します。Lambda を「S3 書き込み」と「ingestion 起動」に分離し、DynamoDB で `last_started_at` を管理するデバウンス機構を入れることを計画しています。

### 追加メニューの分離

現状の「追加」は No 採番 + API 呼び出しを一気に行うため、途中失敗で「No だけ発番済み」が残るリスクがあります。追加を No 採番のみのローカル操作にして、同期は差分更新で初回も含めて upsert する方式に変更すれば、操作が単純になり失敗時の再実行も楽になります。

### 認証の強化

現状は API キーだけで認証しています。漏洩時のリスクを下げるため、Google ID token + Lambda Authorizer の組み合わせを検討しています。GAS から Google の ID トークンを取得し、Lambda Authorizer で検証する方式です。IP 制限は GAS 経由では IP 固定が難しいため注意が必要です。

### 検索精度の検証

ナレッジの件数が少ないうちはスコアの傾向がつかみにくいので、ある程度データを投入してから、表現の揺れに対するスコアの変化を確認したいと考えています。必要に応じて構造化 Markdown テンプレートの調整や、チャンキング戦略の見直しを検討します。

### 監視

Lambda のエラー率を CloudWatch Alarms で監視し、同期に失敗したナレッジが放置されないようにする仕組みを入れていきます。

## まとめ

- スプレッドシートを UI にすることで、ビジネスサイドの学習コストゼロでナレッジ管理ができる
- 構造化 Markdown テンプレート（`## Question` / `## Answer`）で検索品質を均一化
- `job_id` + `row_number` による安全な書き戻しで運用事故を防止
- 論理削除（`active` フラグ）で削除タイミングのずれに対応
- S3 Vectors を使うことで、低コストでベクトル検索環境を構築できる
- GAS → API Gateway → Lambda → S3 → Knowledge Bases の一直線構成で、障害点の切り分けが容易

コード全体は GitHub で公開しています。

https://github.com/tsuka00/aws-knowledge-pipeline
